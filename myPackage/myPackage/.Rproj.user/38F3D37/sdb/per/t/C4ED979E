{
    "collab_server" : "",
    "contents" : "#############################################################\n## Stat 202A - Homework 1\n## Author: Hariharan Shanmugavadivel\n## Date : 10/10/2017\n## Description: This script implements linear regression\n## using Gauss-Jordan elimination in both plain and\n## vectorized forms\n#############################################################\n\n#############################################################\n## INSTRUCTIONS: Please fill in the missing lines of code\n## only where specified. Do not change function names,\n## function inputs or outputs. You can add examples at the\n## end of the script (in the \"Optional examples\" section) to\n## double-check your work, but MAKE SURE TO COMMENT OUT ALL\n## OF YOUR EXAMPLES BEFORE SUBMITTING.\n##\n## Very important: Do not use the function \"setwd\" anywhere\n## in your code. If you do, I will be unable to grade your\n## work since R will attempt to change my working directory\n## to one that does not exist.\n##\n## Do not use the following functions for this assignment,\n## except when debugging or in the optional examples section:\n## 1) lm()\n## 2) solve()\n#############################################################\n\n\n###############################################\n## Function 1: Plain version of Gauss Jordan ##\n###############################################\n\n\nmyGaussJordan <- function(A, m){\n\n  # Perform Gauss Jordan elimination on A.\n  #\n  # A: a square matrix.\n  # m: the pivot element is A[m, m].\n  # Returns a matrix with the identity matrix\n  # on the left and the inverse of A on the right.\n\n  #############################################\n  ## FILL IN THE BODY OF THIS FUNCTION BELOW ##\n  #############################################\n\n  n <- dim(A)[1]\n  B <- cbind(A, diag(rep(1,n)))\n\n\n  for(k in 1:m)\n  {\n    a <- B[k,k]\n\n    for(j in 1:(n*2))\n    {\n      B[k,j] <- B[k,j]/a\n    }\n\n    for(i in 1:n)\n    {\n      if(i != k)\n      {\n        b <- B[i,k]\n\n        for(j in 1:(n*2))\n\n          B[i,j] <- B[i,j] - b*B[k,j]\n\n      }\n    }\n  }\n\n  ## Function returns the matrix B\n\n  return(B)\n\n}\n\n####################################################\n## Function 2: Vectorized version of Gauss Jordan ##\n####################################################\n\nmyGaussJordanVec <- function(A, m){\n\n  # Perform Gauss Jordan elimination on A.\n  #\n  # A: a square matrix.\n  # m: the pivot element is A[m, m].\n  # Returns a matrix with the identity matrix\n  # on the left and the inverse of A on the right.\n\n  #############################################\n  ## FILL IN THE BODY OF THIS FUNCTION BELOW ##\n  #############################################\n\n  n <- dim(A)[1]\n  B <- cbind(A, diag(rep(1,n)))\n\n  for(k in 1:m)\n  {\n    B[k, ] <- B[k, ] / B[k,k]\n\n    for(i in 1:n)\n      if(i != k)\n        B[i,] <- B[i,] - B[k, ] * B[i,k]\n  }\n\n\n  ## Function returns the matrix B\n  return(B)\n\n}\n\n\n\n######################################################\n## Function 3: Linear regression using Gauss Jordan ##\n######################################################\n\nmyLinearRegression <- function(X, Y){\n\n  # Find the regression coefficient estimates beta_hat\n  # corresponding to the model Y = X * beta + epsilon\n  # Your code must use one of the 2 Gauss Jordan\n  # functions you wrote above (either one is fine).\n  # Note: we do not know what beta is. We are only\n  # given a matrix X and a vector Y and we must come\n  # up with an estimate beta_hat.\n  #\n  # X: an 'n row' by 'p column' matrix of input variables.\n  # Y: an n-dimensional vector of responses\n\n  #############################################\n  ## FILL IN THE BODY OF THIS FUNCTION BELOW ##\n  #############################################\n\n  ## Let me start things off for you...\n  n <- nrow(X)\n  p <- ncol(X)\n\n  Z <- cbind(rep(1,n),X, Y)\n  A <- t(Z) %*% Z\n  S <- myGaussJordanVec(A, p+1)\n\n\n  beta_hat <- S[1:(p+1),p+2]\n\n\n  ## Function returns the (p+1)-dimensional vector\n  ## beta_hat of regression coefficient estimates\n  print(beta_hat)\n  return(beta_hat)\n\n}\n\ndata(cars)\nx <- matrix(cars$speed)\ny <- matrix(cars$dist)\nbeta <- myLinearRegression(x,y)\nplot(x, beta[1] + beta[2]*x, type = \"l\", col = \"red\", xlab = \"Distance\", ylab = \"Speed\")\npoints(x, y, col=\"green\", pch=\"*\")\n\n\n\n\n\n\n\n\n",
    "created" : 1511935820062.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2200558818",
    "id" : "C4ED979E",
    "lastKnownWriteTime" : 1511936864,
    "last_content_update" : 1511936864840,
    "path" : "D:/UCLA/Fall 2017/STATS202A - Stats Programming/Assignments/Assignment 7/Linear/Linear.r",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}