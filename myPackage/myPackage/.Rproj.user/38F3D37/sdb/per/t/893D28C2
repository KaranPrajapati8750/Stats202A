{
    "collab_server" : "",
    "contents" : "#############################################################\n## Stat 202A - Homework 6\n## Author: Hariharan Shanmugavadivel\n## Date : 16th November, 2017\n## Description: This script implements ridge regression as\n## well as piecewise linear spline regression.\n#############################################################\n\n#############################################################\n## INSTRUCTIONS: Please fill in the missing lines of code\n## only where specified. Do not change function names,\n## function inputs or outputs. You can add examples at the\n## end of the script (in the \"Optional examples\" section) to\n## double-check your work, but MAKE SURE TO COMMENT OUT ALL\n## OF YOUR EXAMPLES BEFORE SUBMITTING.\n##\n## Very important: Do not use the function \"setwd\" anywhere\n## in your code. If you do, I will be unable to grade your\n## work since R will attempt to change my working directory\n## to one that does not exist.\n#############################################################\n\n## Source your Rcpp file (put in the name of your\n## Rcpp file)\nlibrary(Rcpp)\nsourceCpp('Sweep.cpp')\n\n##################################\n## Function 1: QR decomposition ##\n##################################\n\nmyQR <- function(A){\n\n  ## Perform QR decomposition on the matrix A\n  ## Input:\n  ## A, an n x m matrix\n\n  ########################\n  ## FILL IN CODE BELOW ##\n  ########################\n\n  n <- dim(A)[1]\n  m <- dim(A)[2]\n  R <- A\n  Q <- diag(n)\n\n  for(k in 1:(m-1))\n  {\n    X <- matrix(0, n, 1)\n    X[k:n, 1] <- R[k:n, k]\n    V <- X\n    V[k] <- X[k] + sign(X[k, 1]) * norm(X, type=\"F\")\n    S <- norm(V, type = \"F\")\n\n    if(S!=0)\n    {\n      u <- V/S\n\n      R <- R - (2 * (u %*% (t(u) %*% R)))\n      Q <- Q - (2 * (u %*% (t(u) %*% Q)))\n    }\n\n  }\n\n  ## Function should output a list with Q.transpose and R\n  ## Q is an orthogonal n x n matrix\n  ## R is an upper triangular n x m matrix\n  ## Q and R satisfy the equation: A = Q %*% R\n  return(list(\"Q\" = t(Q), \"R\" = R))\n\n}\n\n\n#################################\n## Function 2: Sweep operation ##\n#################################\n\nmySweep <- function(A, m){\n\n  # Perform a SWEEP operation on A with the pivot element A[m,m].\n  #\n  # A: a square matrix.\n  # m: the pivot element is A[m, m].\n  # Returns a swept matrix.\n\n  ########################\n  ## FILL IN CODE BELOW ##\n  ########################\n\n  n <- dim(A)[1]\n\n  for(k in 1:m)\n  {\n    for(i in 1:n)\n    {\n      for(j in 1:n)\n      {\n        if(i!=k & j!=k)\n        {\n          A[i, j] <- A[i, j] - A[i, k]*A[k, j]/A[k, k]\n        }\n      }\n    }\n\n\n    for(i in 1:n)\n    {\n      if(i!=k)\n      {\n        A[i, k] <- A[i, k]/A[k, k]\n      }\n    }\n\n    for(j in 1:n)\n    {\n      if(j!=k)\n        A[k, j] <- A[k, j]/A[k, k]\n    }\n\n    A[k, k] <- (-1.0)/A[k, k]\n  }\n\n  ## The function outputs the matrix B\n  return(A)\n\n\n}\n\n\n##################################\n## Function 3: Ridge regression ##\n##################################\n\nmyRidge <- function(X, Y, lambda){\n\n  # Perform ridge regression of Y on X.\n  #\n  # X: an n x p matrix of explanatory variables.\n  # Y: an n vector of dependent variables. Y can also be a\n  # matrix, as long as the function works.\n  # lambda: regularization parameter (lambda >= 0)\n  # Returns beta, the ridge regression solution.\n\n  ##################################\n  ## FILL IN THIS SECTION OF CODE ##\n  ##################################\n\n  n = dim(X)[1]\n  p = dim(X)[2]\n  Z = cbind(rep(1, n), X, Y)\n  A = t(Z) %*% Z\n  D = diag(rep(lambda, p+2))\n  D[1, 1] = 0\n  D[p+2, p+2] = 0\n  A = A + D\n  S = mySweepC(A, p+1)\n  beta_ridge = S[1:(p+1), p+2]\n\n\n  # b <- myQR(A)\n\n  #\n  # R <- b$R\n  #\n  # R1 <- R[1:(p+1), 1:(p+1)]\n  # Y1 <- R[1: (p+1), p+2]\n  #\n  # beta_ridge = solve(R1, Y1)\n\n  ## Function should output the vector beta_ridge, the\n  ## solution to the ridge regression problem. beta_ridge\n  ## should have p + 1 elements.\n  return(beta_ridge)\n\n}\n\n\n####################################################\n## Function 4: Piecewise linear spline regression ##\n####################################################\n\n\nmySpline <- function(x, Y, lambda, p = 100){\n\n  # Perform spline regression of Y on X.\n  #\n  # x: An n x 1 vector or matrix of explanatory variables.\n  # Y: An n x 1 vector of dependent variables. Y can also be a\n  # matrix, as long as the function works.\n  # lambda: regularization parameter (lambda >= 0)\n  # p: Number of cuts to make to the x-axis.\n\n  ##################################\n  ## FILL IN THIS SECTION OF CODE ##\n  ##################################\n  n = length(x)\n\n  X = matrix(x, nrow = n)\n  for(k in (1:(p-1)/p)){\n    X = cbind(X, (x>k)*(x-k))\n  }\n\n  beta_spline = myRidge(X, Y, lambda)\n  Yhat = cbind(rep(1, n), X)%*%beta_spline\n\n\n  plot(x, Y, ylim = c(-.2, 1.2), col = \"red\")\n  par(new = TRUE)\n  plot(x, Yhat, ylim = c(-.2, 1.2), type = 'l', col = \"green\")\n\n  ## Function should a list containing two elements:\n  ## The first element of the list is the spline regression\n  ## beta vector, which should be p + 1 dimensional (here,\n  ## p is the number of cuts we made to the x-axis).\n  ## The second element is y.hat, the predicted Y values\n  ## using the spline regression beta vector. This\n  ## can be a numeric vector or matrix.\n  output <- list(beta_spline = beta_spline, predicted_y = Yhat)\n  return(output)\n\n}\n\n# # Plot times\n#    n    <- 20\n#    p    <- 500\n#    sigma = 0.1\n#\n#   print(paste0(\"Execution time for N= \", n, \" P= \", p))\n#\n#   # Time myQR\n#   x = runif(n)\n#   x = sort(x)\n#   Y = x^2 + rnorm(n)*sigma\n#   startTime = proc.time()\n#   mySpline(x, Y, 100, p)\n#   stopTime = proc.time()\n#   print(\"R\")\n#   print(stopTime - startTime)\n\n\n\n# \n#   error <- function(Yhat,Y)\n#   {\n#     return (mean((Yhat-Y)^2))\n#   }\n#   n = 50\n#   n_train = ceiling(2*n/3)\n#   n_test = n-n_train\n#   p = 1000\n#   sigma = .1\n#   lambda = 10.\n#   x = runif(n)\n# \n#   train_ind =sample(1:n,n_train)\n#   test_ind = setdiff(1:n,train_ind)\n# \n#   #x_train1 = sample(x, size = n_train, replace = FALSE)\n#   #x_train = sort(x_train1)\n#   x_train = sort(x[train_ind]) # x\n#   y_train = x_train^2 + rnorm(n_train)*sigma #n\n#   Y_train = matrix(y_train, nrow=n_train) #n\n#   x_test = sort(x[test_ind])\n#   #x_test1 = setdiff(x,x_train1)\n#   #x_test = sort(x_test1)\n#   y_test = x_test^2 + rnorm(n_test)*sigma\n#   Y_test = matrix(y_test, nrow=n_test)\n#   X_train = matrix(x_train, nrow=n_train)\n#   X_test = matrix(x_test, nrow=n_test)\n#   error_test = NULL\n#   error_train = NULL\n# \n#   for (k in (1:(p-1))/p){\n#     X_test = cbind(X_test, (x_test>k)*(x_test-k))\n#   }\n# \n#   Y_total=NULL\n#   for(lambda in 1:100){\n#     Y_total=mySpline(X_train, Y_train, lambda, p)\n# \n#     beta_spline = Y_total[[1]]\n#     Yhat_train = Y_total[[2]]\n# \n#     Yhat_test = cbind(rep(1, n_test), X_test)%*%beta_spline\n# \n#     error_train = append(error_train,error(Yhat_train,Y_train))\n#     error_test = append(error_test,error(Yhat_test,Y_test))\n#   }\n#   lambda1 = 1:100\n# \n#   plot(lambda1,error_train,col=\"red\",xlab=\"Lambda\",ylab=\"Error\",type=\"p\")\n#   par(new = TRUE)\n#   plot(lambda1,error_test,col=\"green\",xlab=\"Lambda\",ylab=\"Error\",type=\"p\")\n",
    "created" : 1511938000702.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2331588866",
    "id" : "893D28C2",
    "lastKnownWriteTime" : 1510901617,
    "last_content_update" : 1510901617,
    "path" : "D:/UCLA/Fall 2017/STATS202A - Stats Programming/Assignments/Assignment 6/Answers/Ridge_Spline.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}